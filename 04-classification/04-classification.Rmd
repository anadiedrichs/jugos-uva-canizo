---
title: "clasificacion"
author: "Ana Diedrichs"
date: "May 22, 2019"
output:
  pdf_document: default
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```
```{r}
library(ggplot2)
suppressMessages(library(tidyverse))
```

# Datos


```{r,echo = FALSE}
# cargamos los datos 
library(readxl)
dataset <- read_excel("../data/Dataset para enfoque 2 y 3.xlsx")
dataset <- dataset %>% filter(Origen != "CH")
# escalamos dataset en valores 0 a 1
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
data <- data.frame(dataset[,1], apply(dataset[-1],2,range01))
# desordenamos el dataset
data <- data[sample(1:nrow(dataset)),]
# cual es la variable de clase HARDCODEO
Y <- 1 # COLUMNA 1 
```

Este dataset tiene `r ncol(data)` variables en total, contando la variable de clase llamada `r colnames(data)[Y]`. El dataset consta de `r nrow(data)` datapoints o muestras clasificadas en `r length(unique(data[,Y]))` clases etiquetadas como `r unique(data[,Y])`

En el siguiente cuadro y gráfico observamos como se distribuyen las muestras según su origen. 
Notamos que el dataset está desbalanceado, pues no hay la misma cantidad de datapoints para cada clase.

```{r results='asis',echo = FALSE}

d <- data %>% group_by(Origen) %>% summarise(n = n())
knitr::kable(d, caption = "Tabla que muestra distribución de datapoints por clase")
```
```{r}

myplot <- ggplot(data=d, aes(x=Origen, y=n)) +
  geom_bar(stat="identity", fill="steelblue")+
  theme_minimal()

print(myplot)
```
# Experimentos

Sobre el total del dataset emplearemos k-fold cross validation con k=4 para los modelos:

* LDA linear discriminant analysis
* nnet neural networks

Al final se muestran los resultados de los modelos sobre cross validation, agrupados.


## LDA 

```{r}
library(caret)
x = data[,-1]
y = data$Origen
#index <- sample(1:nrow(data), round(nrow(data) * 0.7))
#train <- data[index,]
#test <- data[-index,]
SEED <- 1234 # seed semilla para números aleatorios
set.seed(SEED)
mySeeds <- sapply(simplify = FALSE, 1:11, function(u) sample(10^4, 3))

METRIC <- "Accuracy" #
train_control <- trainControl(method="cv", number=4,seeds = mySeeds,classProbs=TRUE)

set.seed(SEED)
mySeeds <- sapply(simplify = FALSE, 1:11, function(u) sample(10^4, 3))
train_control <- trainControl(method="cv", number=4,seeds = mySeeds,classProbs=TRUE)
model.lda <- train(as.factor(Origen)~., data=data, 
                  trControl=train_control, method="lda",metric=METRIC)

p <- predict(model.lda$finalModel,x,type="class")

```

```{r}
print(table(p$class,y))
```

## Neural network
```{r}

my.grid <- expand.grid(.decay = c(0.5, 0.1), .size = c(5, 6, 7))

set.seed(SEED)
mySeeds <- sapply(simplify = FALSE, 1:11, function(u) sample(10^4, 6))
train_control <- trainControl(method="cv", number=4,seeds = mySeeds,classProbs=TRUE)
model.nnet <- train(as.factor(Origen)~., data=data, 
                  trControl=train_control, method="nnet", tuneGrid=my.grid,
                  maxit = 1000, trace = F,metric=METRIC)

p <- predict(model.nnet$finalModel,x,type="class")

print(table(p,y))

```
```{r}

plot(model.nnet)
```

## glmnet

```{r}

set.seed(SEED)
mySeeds <- sapply(simplify = FALSE, 1:11, function(u) sample(10^4, 3))

train_control <- trainControl(method="cv", number=4,seeds = mySeeds,classProbs=TRUE)
model.glmnet <- train(as.factor(Origen)~., data=data, 
                  trControl=train_control, method="glmnet",metric=METRIC)

p <- predict(model.glmnet$finalModel,x,type="class") # <--- TIRA ERROR TODO 

```

```{r}
# <--- TIRA ERROR TODO 
print(table(p$class,y))
```

## Comparación modelos
```{r}

results <- resamples(list(LDA=model.lda,nnet=model.nnet))
# summarize the distributions
summary(results)
# boxplots of results
bwplot(results)
# dot plots of results
dotplot(results)

```
Observamos que  la red neuronal tuvo un mejor desempeño que LDA.

## **TODO agregar algo con bootstrapping ??**

# chusmeando que daba random forest

```{r}
#' ## Random Forest
#' 
set.seed(SEED)
model.rf <- train(as.factor(Origen)~., data=data, 
                  trControl=train_control, method="rf",metric=METRIC, importance=T)

#'  ### Results of random forest model
print(model.rf)
plot(model.rf)
print(model.rf$finalModel)
#' ### Variable importance
varImp(model.rf)
plot(varImp(model.rf))
#' Predicción en conjunto de testeo test-set
pred <- predict(model.rf,data)
c <- confusionMatrix(as.factor(pred), as.factor(data$Origen),mode = "prec_recall")
print(c)
```

